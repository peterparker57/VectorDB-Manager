# ADR-078: Fix LLM Models Tab Issue

## Status

Accepted

## Context

The LLM Models tab in the VectorDB-Manager application was showing an error "Failed to load providers" while the providers were loading fine in the Providers tab. This issue was preventing users from managing their LLM models effectively.

After investigation, the issue was identified in how the LLM provider API was exposed to the renderer process:

1. The `setupLLMProviderAPI()` function in `preload.ts` was being called, but there was an issue with how the API was being exposed to the renderer process.
2. The `window.llmProvider.listProviders()` function was failing in the LLM Models tab, causing the "Failed to load providers" error.
3. The Providers tab was working fine because it was using a different API (`window.modelCatalog.getProviderTypes()`).

## Decision

Enhance the preload script to properly expose the LLM provider API to the renderer process:

1. Create a direct implementation of the LLM provider API in the preload script with proper TypeScript typing.
2. Add comprehensive error handling for all API methods.
3. Add detailed logging to help diagnose any issues.
4. Remove the call to `setupLLMProviderAPI()` to prevent the "Cannot bind an API on top of an existing property on the window object" error.

## Consequences

### Positive

- The LLM Models tab now loads providers correctly without showing the "Failed to load providers" error.
- The application is now fully functional with both the Providers tab and LLM Models tab working correctly.
- The enhanced error handling and logging make it easier to diagnose any future issues.
- The proper TypeScript typing improves code quality and prevents compilation errors.

### Negative

- The solution adds some duplication in the API implementation, as the LLM provider API is now implemented directly in the preload script instead of being generated by a helper function.
- The preload script is now larger and more complex, which may make it harder to maintain in the future.

## Implementation

The implementation includes:

1. Creating a robust implementation of the LLM provider API with detailed logging and error handling:

```typescript
const llmProviderApi = {
  listProviders: async () => {
    console.log('Calling llmProvider.listProviders');
    try {
      const providers = await ipcRenderer.invoke('llm-provider:list');
      console.log('llmProvider.listProviders response:', providers);
      return { success: true, providers };
    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error('llmProvider.listProviders error:', error);
      return { success: false, providers: [], error: errorMessage };
    }
  },
  // ... other methods
};
```

2. Ensuring the API is properly exposed through the Electron contextBridge:

```typescript
// Expose the llmProvider API
contextBridge.exposeInMainWorld('llmProvider', llmProviderApi);

// Do NOT call setupLLMProviderAPI() here as it would try to expose the API again
```

3. Adding proper TypeScript typing to all methods to prevent compilation errors.

## Notes

This fix addresses the immediate issue of the LLM Models tab not loading providers correctly, but there may be underlying issues with the API design that should be addressed in the future. A more comprehensive solution would be to standardize the API design across the application and ensure that all APIs are properly typed and documented.
